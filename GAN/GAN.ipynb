{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4pJ4DHFZ1To",
        "outputId": "c7f13055-c28e-4fdf-a280-77814e0ed454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 17.7MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 479kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.44MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 11.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50]  D Loss: 0.0391  G Loss: 6.5052\n",
            "Epoch [2/50]  D Loss: 0.0247  G Loss: 10.2173\n",
            "Epoch [3/50]  D Loss: 0.2784  G Loss: 7.0374\n",
            "Epoch [4/50]  D Loss: 0.3516  G Loss: 9.4681\n",
            "Epoch [5/50]  D Loss: 0.7943  G Loss: 3.9339\n",
            "Epoch [6/50]  D Loss: 0.8930  G Loss: 2.4434\n",
            "Epoch [7/50]  D Loss: 0.9027  G Loss: 1.7047\n",
            "Epoch [8/50]  D Loss: 0.4572  G Loss: 2.3680\n",
            "Epoch [9/50]  D Loss: 0.6267  G Loss: 2.1660\n",
            "Epoch [10/50]  D Loss: 0.9494  G Loss: 1.4111\n",
            "Epoch [11/50]  D Loss: 1.3591  G Loss: 0.9439\n",
            "Epoch [12/50]  D Loss: 0.4286  G Loss: 2.1348\n",
            "Epoch [13/50]  D Loss: 0.2814  G Loss: 3.0554\n",
            "Epoch [14/50]  D Loss: 0.7245  G Loss: 3.0511\n",
            "Epoch [15/50]  D Loss: 0.8021  G Loss: 2.3209\n",
            "Epoch [16/50]  D Loss: 0.6389  G Loss: 5.6900\n",
            "Epoch [17/50]  D Loss: 0.3148  G Loss: 4.9226\n",
            "Epoch [18/50]  D Loss: 0.2203  G Loss: 6.1628\n",
            "Epoch [19/50]  D Loss: 0.0330  G Loss: 6.8429\n",
            "Epoch [20/50]  D Loss: 0.1397  G Loss: 4.8779\n",
            "Epoch [21/50]  D Loss: 0.0679  G Loss: 10.8177\n",
            "Epoch [22/50]  D Loss: 0.3811  G Loss: 7.2194\n",
            "Epoch [23/50]  D Loss: 0.1854  G Loss: 4.9723\n",
            "Epoch [24/50]  D Loss: 0.3040  G Loss: 6.3438\n",
            "Epoch [25/50]  D Loss: 0.2594  G Loss: 5.3354\n",
            "Epoch [26/50]  D Loss: 0.2726  G Loss: 5.6151\n",
            "Epoch [27/50]  D Loss: 0.3582  G Loss: 3.1430\n",
            "Epoch [28/50]  D Loss: 0.1518  G Loss: 5.0258\n",
            "Epoch [29/50]  D Loss: 0.9023  G Loss: 4.4585\n",
            "Epoch [30/50]  D Loss: 0.2845  G Loss: 4.1478\n",
            "Epoch [31/50]  D Loss: 0.4088  G Loss: 6.3521\n",
            "Epoch [32/50]  D Loss: 0.3299  G Loss: 3.1381\n",
            "Epoch [33/50]  D Loss: 0.5395  G Loss: 3.9585\n",
            "Epoch [34/50]  D Loss: 0.4631  G Loss: 4.3529\n",
            "Epoch [35/50]  D Loss: 0.4029  G Loss: 4.0678\n",
            "Epoch [36/50]  D Loss: 0.4081  G Loss: 4.1831\n",
            "Epoch [37/50]  D Loss: 0.6955  G Loss: 4.0042\n",
            "Epoch [38/50]  D Loss: 0.5181  G Loss: 3.5277\n",
            "Epoch [39/50]  D Loss: 0.5107  G Loss: 4.6456\n",
            "Epoch [40/50]  D Loss: 0.7191  G Loss: 4.1482\n",
            "Epoch [41/50]  D Loss: 0.8644  G Loss: 4.2930\n",
            "Epoch [42/50]  D Loss: 0.3761  G Loss: 3.4970\n",
            "Epoch [43/50]  D Loss: 0.5430  G Loss: 2.9410\n",
            "Epoch [44/50]  D Loss: 0.4965  G Loss: 3.1774\n",
            "Epoch [45/50]  D Loss: 0.5782  G Loss: 4.6992\n",
            "Epoch [46/50]  D Loss: 0.5757  G Loss: 3.0882\n",
            "Epoch [47/50]  D Loss: 0.3068  G Loss: 3.3397\n",
            "Epoch [48/50]  D Loss: 0.4417  G Loss: 3.5201\n",
            "Epoch [49/50]  D Loss: 0.3763  G Loss: 2.7461\n",
            "Epoch [50/50]  D Loss: 0.7164  G Loss: 4.1095\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image, make_grid\n",
        "import os\n",
        "\n",
        "# Settings\n",
        "latent_dim = 100\n",
        "epochs = 50\n",
        "batch_size = 128\n",
        "sample_dir = 'gan_samples'\n",
        "\n",
        "os.makedirs(sample_dir, exist_ok=True)\n",
        "\n",
        "# Data Loader\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])  # normalize to [-1, 1]\n",
        "])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST(root='.', train=True, transform=transform, download=True),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Generator\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 256),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(1024, 28 * 28),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        out = self.model(z)\n",
        "        return out.view(z.size(0), 1, 28, 28)\n",
        "\n",
        "# Discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(28 * 28, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        img_flat = img.view(img.size(0), -1)\n",
        "        return self.model(img_flat)\n",
        "\n",
        "# Initialize models\n",
        "G = Generator()\n",
        "D = Discriminator()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "G.to(device)\n",
        "D.to(device)\n",
        "\n",
        "# Loss and optimizers\n",
        "loss_fn = nn.BCELoss()\n",
        "g_optimizer = optim.Adam(G.parameters(), lr=0.0002)\n",
        "d_optimizer = optim.Adam(D.parameters(), lr=0.0002)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    for real_imgs, _ in train_loader:\n",
        "        real_imgs = real_imgs.to(device)\n",
        "        batch_size = real_imgs.size(0)\n",
        "\n",
        "        # Labels\n",
        "        real_labels = torch.ones(batch_size, 1).to(device)\n",
        "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "        # Train Discriminator\n",
        "        z = torch.randn(batch_size, latent_dim).to(device)\n",
        "        fake_imgs = G(z)\n",
        "        real_loss = loss_fn(D(real_imgs), real_labels)\n",
        "        fake_loss = loss_fn(D(fake_imgs.detach()), fake_labels)\n",
        "        d_loss = real_loss + fake_loss\n",
        "\n",
        "        d_optimizer.zero_grad()\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "\n",
        "        # Train Generator\n",
        "        z = torch.randn(batch_size, latent_dim).to(device)\n",
        "        fake_imgs = G(z)\n",
        "        g_loss = loss_fn(D(fake_imgs), real_labels)\n",
        "\n",
        "        g_optimizer.zero_grad()\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "    # Save samples\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}]  D Loss: {d_loss.item():.4f}  G Loss: {g_loss.item():.4f}\")\n",
        "    with torch.no_grad():\n",
        "        test_z = torch.randn(64, latent_dim).to(device)\n",
        "        generated = G(test_z)\n",
        "        save_image(generated, f\"{sample_dir}/epoch_{epoch+1:03d}.png\", normalize=True, nrow=8)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "import glob\n",
        "\n",
        "images = []\n",
        "for filename in sorted(glob.glob('gan_samples/epoch_*.png')):\n",
        "    images.append(imageio.imread(filename))\n",
        "imageio.mimsave('gan_training.gif', images, duration=0.5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6p9PAl1kaCu2",
        "outputId": "838f88fb-87d9-455c-993c-08f1cb97552b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-4ff42e9c7c64>:6: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  images.append(imageio.imread(filename))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming we've stored loss values during training\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(d_losses, label='Discriminator Loss')\n",
        "plt.plot(g_losses, label='Generator Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.title('GAN Training Loss')\n",
        "plt.savefig('loss_curve.png')\n",
        "plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "9TECQk9voH18",
        "outputId": "9de128ee-8d25-493a-e7e3-fb8a6df20334"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-df0b8cd44f2a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Assuming we've stored loss values during training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Discriminator Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Generator Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    }
  ]
}